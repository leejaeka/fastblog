{
  
    
        "post0": {
            "title": "LoL Prediction S11",
            "content": "Introduction . Riot Games brings massive changes to their game &#39;League of Legend&#39; every year. This year, they changed their item system, drastically changing their game ecosystem. It has been few months since the big update and now players have fully adapted to the changes. Let&#39;s take a look at what happened to the ecosystem and what is the best team composition now. . Find out what are the most popular champions now. | Find out which team composition is the best. | Compare Season 10 and pre-Season 11. How did the item changes impact the game? | . The dataset . The data we are going to use is a csv file obtained from scraping op.gg which is a website with League of Legend statistics. If you are interested you can visit here. The dataset consists of 2901 ranked matches from Korea(WWW), North America(NA), Eastern Europe(EUNE), and Western Europe(EUW) servers. It has which team won the match, the total time of the match, blue team composition and red team composition. Note that only the high elo games were added this includes Challenger, Grand Master, Master and sometimes even High Diamonds. Note that there are 153 total unique champions with &#39;Rell&#39; as the latest addition. Duplicate games have been removed. . import numpy as np import pandas as pd import matplotlib.pyplot as plt from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split from sklearn.metrics import r2_score, mean_squared_error import seaborn as sns from sklearn.utils import shuffle %matplotlib inline . df = pd.read_csv (&#39;data/s11.csv&#39;) df = shuffle(df) df.head() . result server team_1__001 team_1__002 team_1__003 team_1__004 team_1__005 team_2__001 team_2__002 team_2__003 team_2__004 team_2__005 timestamp game_length . 1265 Defeat | www | Camille | Hecarim | Neeko | Aphelios | Sett | Rumble | Kayn | Twisted Fate | Miss Fortune | Leona | 2020-12-07 18:48:25 | 34m 23s | . 1958 Defeat | eune | Kennen | Rengar | Kassadin | Miss Fortune | Bard | Kayle | Graves | Fiora | Caitlyn | Thresh | 2020-12-18 18:26:55 | 16m 12s | . 1877 Victory | euw | Mordekaiser | Olaf | Zoe | Jhin | Alistar | Shen | Hecarim | LeBlanc | Aphelios | Galio | 2020-12-30 08:58:13 | 34m 27s | . 778 Victory | www | Aatrox | Elise | Lucian | Miss Fortune | Pantheon | Camille | Graves | Zoe | Jhin | Leona | 2020-12-29 21:49:55 | 18m 56s | . 2591 Defeat | na | Poppy | Kayn | Akali | Senna | Braum | Volibear | Olaf | Yone | Twisted Fate | Janna | 2020-11-10 07:38:39 | 31m 15s | . Data Cleaning . Change game_length to continuous variable | Clean null values and uninformative columns | Change categorical variables to dummy variables | import re date_str = df.game_length for i in range(len(date_str)): if type(date_str[i]) == str: p = re.compile(&#39; d*&#39;) min = float(p.findall(date_str[i][:2])[0]) temp = p.findall(date_str[i][-3:]) for j in temp: if j != &#39;&#39;: sec = float(j) break date_str[i] = (60*min+sec) else: date_str[i] = date_str[i] # print(date_str[i]) # print(len(date_str)) # remove timestamp since it does not affect the game df = df.drop([&#39;timestamp&#39;], axis=1) . df.describe() . result server team_1__001 team_1__002 team_1__003 team_1__004 team_1__005 team_2__001 team_2__002 team_2__003 team_2__004 team_2__005 game_length . count 2901 | 2901 | 2901 | 2901 | 2901 | 2901 | 2901 | 2901 | 2901 | 2901 | 2901 | 2901 | 2901.0 | . unique 2 | 4 | 96 | 62 | 102 | 70 | 56 | 95 | 58 | 102 | 72 | 63 | 235.0 | . top Defeat | www | Camille | Graves | Akali | Jhin | Leona | Camille | Graves | Yone | Kai&#39;Sa | Leona | 1818.0 | . freq 2271 | 1592 | 305 | 581 | 235 | 590 | 355 | 266 | 504 | 226 | 568 | 381 | 100.0 | . Most popular champions . Camille(Top), Graves(Jg), Akali/Yone(Mid), Jhin/Kai&#39;sa(Adc), Leona(Supp) | . Notes: . The result is very skewed because there are 2271 Red Team win compared to only 630 Blue Team wins | There are in total 2901 games and more than half of it is from Korean server | . no_nulls = set(df.columns[df.isnull().sum()==0]) print(no_nulls) . {&#39;result&#39;, &#39;server&#39;, &#39;team_1__004&#39;, &#39;team_2__003&#39;, &#39;team_1__001&#39;, &#39;team_2__005&#39;, &#39;team_1__003&#39;, &#39;team_2__001&#39;, &#39;game_length&#39;, &#39;team_1__002&#39;, &#39;team_1__005&#39;, &#39;team_2__004&#39;, &#39;team_2__002&#39;} . So there are no null values which is good! . cat_cols = [&#39;result&#39;, &#39;server&#39;, &#39;team_1__004&#39;, &#39;team_2__003&#39;, &#39;team_1__001&#39;, &#39;team_2__005&#39;, &#39;team_1__003&#39;, &#39;team_2__001&#39;,&#39;team_1__002&#39;, &#39;team_1__005&#39;, &#39;team_2__004&#39;, &#39;team_2__002&#39;] def create_dummy_df(df, cat_cols): &#39;&#39;&#39; INPUT: df - pandas dataframe with categorical variables you want to dummy cat_cols - list of strings that are associated with names of the categorical columns OUTPUT: df - new dataframe with following characteristics: 1. contains all columns that were not specified as categorical 2. removes all the original columns in cat_cols 3. dummy columns for each of the categorical columns in cat_cols 4. Use a prefix of the column name with an underscore (_) for separating &#39;&#39;&#39; for col in cat_cols: try: df = pd.concat([df.drop(col, axis=1), pd.get_dummies(df[col], prefix=col, prefix_sep=&#39;_&#39;, drop_first=True)], axis=1) except: continue return df . df = create_dummy_df(df, cat_cols) . max_time = max(df[&#39;game_length&#39;]) df=pd.concat([df.drop(&#39;game_length&#39;, axis=1), (df[&#39;game_length&#39;]/max_time)], axis=1) . df.head(10) . result_Victory server_euw server_na server_www team_1__004_Akali team_1__004_Anivia team_1__004_Annie team_1__004_Aphelios team_1__004_Ashe team_1__004_Aurelion Sol ... team_2__002_Udyr team_2__002_Urgot team_2__002_Vi team_2__002_Volibear team_2__002_Warwick team_2__002_Wukong team_2__002_Xin Zhao team_2__002_Zac team_2__002_Zed game_length . 1265 0 | 0 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.700272 | . 1958 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.329939 | . 1877 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.701629 | . 778 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.385608 | . 2591 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.636456 | . 655 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.517651 | . 1089 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.700272 | . 1221 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.617108 | . 1480 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.419212 | . 1791 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | ... | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0.556687 | . 10 rows × 771 columns . The data is ready for modelling. . Linear Regression . y = df[&#39;result_Victory&#39;] X = df.drop([&#39;result_Victory&#39;], axis = 1) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42) lm_model = LinearRegression(normalize=True) . lm_model.fit(X_train, y_train) . LinearRegression(normalize=True) . test_pred = lm_model.predict(X_test) train_pred = lm_model.predict(X_train) r2_test = r2_score(y_test, test_pred) r2_train = r2_score(y_train, train_pred) print(&quot;test r2: &quot;+str(r2_test)) print(&quot;train r2: &quot;+str(r2_train)) . test r2: -2.7134011717466985e+28 train r2: 0.25972262531839096 . test_acc = np.sum(y_test == test_pred)/len(y_test) train_acc = np.sum(y_train == train_pred)/len(y_train) print(&quot;test accuracy: &quot;+str(test_acc)) print(&quot;train accuracy: &quot;+str(train_acc)) . test accuracy: 0.0 train accuracy: 0.0 . Clearly, linear regression is a poor model for this problem haha. Makes sense since we only have discrete fields except game_length. . def coef_weights(coefficients, X_train): &#39;&#39;&#39; INPUT: coefficients - the coefficients of the linear model X_train - the training data, so the column names can be used OUTPUT: coefs_df - a dataframe holding the coefficient, estimate, and abs(estimate) Provides a dataframe that can be used to understand the most influential coefficients in a linear model by providing the coefficient estimates along with the name of the variable attached to the coefficient. &#39;&#39;&#39; coefs_df = pd.DataFrame() coefs_df[&#39;est_int&#39;] = X_train.columns coefs_df[&#39;coefs&#39;] = lm_model.coef_ coefs_df[&#39;abs_coefs&#39;] = np.abs(lm_model.coef_) coefs_df = coefs_df.sort_values(&#39;abs_coefs&#39;, ascending=False) return coefs_df . coef_df = coef_weights(lm_model.coef_, X_train) coef_df.head(20) . est_int coefs abs_coefs . 435 team_2__001_Aphelios | 7.451403e+14 | 7.451403e+14 | . 689 team_2__004_Sion | -7.451403e+14 | 7.451403e+14 | . 298 team_2__005_Ornn | 5.132176e+14 | 5.132176e+14 | . 248 team_1__001_Sona | -5.052884e+14 | 5.052884e+14 | . 31 team_1__004_Kindred | -4.224175e+14 | 4.224175e+14 | . 43 team_1__004_Pantheon | 4.184556e+14 | 4.184556e+14 | . 282 team_2__005_Jayce | 4.156125e+14 | 4.156125e+14 | . 635 team_1__005_Yasuo | 3.822057e+14 | 3.822057e+14 | . 595 team_1__005_Ekko | 3.822057e+14 | 3.822057e+14 | . 412 team_1__003_Thresh | -3.822057e+14 | 3.822057e+14 | . 79 team_2__003_Bard | 3.781834e+14 | 3.781834e+14 | . 328 team_2__005_Zoe | -3.772819e+14 | 3.772819e+14 | . 19 team_1__004_Gragas | 3.742793e+14 | 3.742793e+14 | . 548 team_1__002_Leona | -3.660990e+14 | 3.660990e+14 | . 611 team_1__005_Nidalee | 3.660990e+14 | 3.660990e+14 | . 526 team_1__002_Camille | -3.586479e+14 | 3.586479e+14 | . 382 team_1__003_Miss Fortune | 3.339794e+14 | 3.339794e+14 | . 5 team_1__004_Annie | 3.293351e+14 | 3.293351e+14 | . 576 team_1__002_Twitch | 3.012684e+14 | 3.012684e+14 | . 292 team_2__005_Miss Fortune | 2.971517e+14 | 2.971517e+14 | . Recall that 1 = Blue win and 0 = Red win. So positive coefs. here means helpful for the Blue team and negative coefs. means helpful for the Red team. Most of the fields in the top 20 table above, are not something we see often. For example 435-aphelios(top), 689-sion(adc), 248-sona(top) are considered troll. Here are some other findings. . Looks like every lane is somewhat equally important as their appearance in the table above are similiar | Most of these are troll picks negatively affecting its own team&#39;s winrate | Picks that are actually helping team&#39;s winrate: Sion(ADC), Pantheon(ADC), Yasuo(Sup)??, Ekko(Sup)?? | This table raises more questions than answers! | . Random Forests . from sklearn.ensemble import RandomForestClassifier rnd_clf = RandomForestClassifier(n_estimators=2000, max_leaf_nodes=32, n_jobs=-1) rnd_clf.fit(X_train, y_train) . RandomForestClassifier(max_leaf_nodes=32, n_estimators=2000, n_jobs=-1) . y_test_pred = rnd_clf.predict(X_test) test_acc = np.sum(y_test_pred == y_test)/len(y_test) print(&quot;test accuracy: &quot;+str(test_acc)) . test accuracy: 0.8003442340791739 . Wow we went from 0% to 80% accuracy with random forest! . import shap explainer = shap.TreeExplainer(rnd_clf) shap_values = explainer.shap_values(X_test) shap.summary_plot(shap_values[1], X_test) . Interestingly, West Europe tend to win more as Blue team as games are longer. In contrast, Korea tend to win more as Red Team as games gets longer. So there seem to be a trend difference between regions. Furthermore, in general, the shorter the game, blue team wins more for some reason I cannot figure out. . Best/Worst Composition . Best . (Top)Camille,Yone (Jg)Hecarim,Olaf,Twitch (Mid)Akali (Adc)Miss Fortune,Jhin (Sup)Alistar,Janna,Leona | . Worst . (Top)Pantheon,Irelia (Jg)Wukong (Mid)Sylas,Yone | . If we compare this with the official na.op.gg champion rankings, all the best champions listed here are also listed on their website as either tier one or two as well. (Except Twitch and Pantheon). Note that this is just for comparison. Op.gg has million times more data with more regions. Also how they rank these champions are not revealed. . Comparing with S10 . Last season&#39;s October data result . Best: (Top)Renekton/Jax/Sylas (Jg)Kindred (Mid) Cassiopeia/Orianna (Adc)MF/Ashe (Sup)Thresh/Rakan | Worst: (Top)Volibear/Trynd/Riven/Lucian (Mid)Akali (Adc)Caitlyn/Kalista (Sup)Janna | . Analysis: . The new update caused each roles to distribute more evenly to winning. | Bottom lane has generally good picks with no worst picks in season 11. | The new update caused more &#39;high risk high reward&#39; champions to win more. | .",
            "url": "https://leejaeka.github.io/fastblog/python/jupyter/crisp-dm/league%20of%20legends/linear%20regression/random%20forest/udacity/2020/12/30/lolpredict2.html",
            "relUrl": "/python/jupyter/crisp-dm/league%20of%20legends/linear%20regression/random%20forest/udacity/2020/12/30/lolpredict2.html",
            "date": " • Dec 30, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "MOOC certificates",
            "content": "I don&#39;t know what to do with these so I put them here! . Coursera . Standford Machine Learning (unofficial) | Convolutional Neural Networks | Sequence Models | Neural Networks and Deep Learning | . Udacity . Data Scientist Nanodegree (in progress) | . Kaggle . Deep Learning | Feature Engineering | Intro to Machine Learning | Intermediate Machine Learning | Machine Learning Explainability | Natural Language Processing | . Udemy . Tableau 20 Advanced Training: Master Tableau in Data Science | Tableau 2020 A-Z: Hands-On Tableau Training for Data Science | Scala and Spark for Big Data and Machine Learning | . .",
            "url": "https://leejaeka.github.io/fastblog/fastpages/jupyter/certificate/2020/12/30/certificates.html",
            "relUrl": "/fastpages/jupyter/certificate/2020/12/30/certificates.html",
            "date": " • Dec 30, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Deep Art Gallery",
            "content": ". This is me when I went to Aachen This is my friend Annan&#39;s puppy, Newbie This is Coquitlam, Canada where I spent my high school years! We used to be forced to do laps around this lake! This is meemaw. How many person in this photo? This was outside my room in Toronto and when I was high This is my handsome friend Truman Hung! It has no idea what to do with my hair lol Styles used . I think you can guess which styles were used on which photos. Except Newbie&#39;s style is by Wassily Kandinsky — Composition VII . How it works . Neural Style Transfer works by choosing a content image and a style image and then &#39;drawing&#39; the content image using style of the style image. . In implementation, all we are doing is calculating some derivatives to make a number small as possible. . This is the cost function we are trying to minimize. As $J(GeneratedImage)$ gets smaller, we get the art we want. Think of cost function as distance from our art being beautiful. G is initialized as a random noise image. We will use Adam optimization to compute the gradient. Think of gradient as small step towards prettiness. . . So every iteration, G will be subtracted with gradient of $J(GeneratedImage)$ slowly becoming beautiful. . . Content Cost Function $J_{content}(C,G)$ . $$J_{content}(C,G) = frac{1}{4 times n_H times n_W times n_C} sum _{ text{all entries}} (a^{(C)} - a^{(G)})^2 tag{1} $$ . Here, $a$ stands for activation of the lth layer in our convNet. | $n_H$, $n_W$, $n_C$ is the dimension of the layer. (Height, width, depth). | The constants in front are just for normalization. | . Style Cost Function $J_{style}(S,G)$ . $$J_{style}^{[l]}(S,G) = frac{1}{4 times {n_C}^2 times (n_H times n_W)^2} sum _{i=1}^{n_C} sum_{j=1}^{n_C}(G^{(S)}_{(gram)i,j} - G^{(G)}_{(gram)i,j})^2 tag{2} $$ . The constants in front are just for normalization | The gram is a function that just calculates the correlation between horizontal vectors in the given matrix(which is our depths) | We will calculate gram of activation layer from both content and generated layer for all combinations of depths(i,j). | And this is just one layer. Then we compute for all layers. This is why it takes so long to generate our image. | Note that the picture below &#39;unrolled&#39; a 3d volume into 2d matrix. | As you can see style cost function is less straightforward. &quot;If you don&#39;t understand it, don&#39;t worry about it&quot; - Andrew NG. | . Code . Cred to Tensorflow (see reference) Note that most of the arts generated above were using code from a coursera assignment which is different from codes below showing implementation (same but different transferred model) in tensorflow2. Modified to run on gpu. . content_image = load_img(&#39;images/newby.jpg&#39;) style_image = load_img(&#39;images/kandinsky.jpg&#39;) plt.subplot(1, 2, 1) imshow(content_image, &#39;Content Image&#39;) plt.subplot(1, 2, 2) imshow(style_image, &#39;Style Image&#39;) . def tensor_to_image(tensor): tensor = tensor*255 tensor = np.array(tensor, dtype=np.uint8) if np.ndim(tensor)&gt;3: assert tensor.shape[0] == 1 tensor = tensor[0] return PIL.Image.fromarray(tensor) . Transfer Learning . Choice for the model is VGG19 since it is what was used in the original paper by Leon A. Gatys, Alexander S. Ecker, Matthias Bethge. . content_layers = [&#39;block5_conv2&#39;] style_layers = [&#39;block1_conv1&#39;, &#39;block2_conv1&#39;, &#39;block3_conv1&#39;, &#39;block4_conv1&#39;, &#39;block5_conv1&#39;] num_content_layers = len(content_layers) num_style_layers = len(style_layers) . def vgg_layers(layer_names): &quot;&quot;&quot; Creates a vgg model that returns a list of intermediate output values.&quot;&quot;&quot; # Load our model. Load pretrained VGG, trained on imagenet data vgg = tf.keras.applications.VGG19(include_top=False, weights=&#39;imagenet&#39;) vgg.trainable = False outputs = [vgg.get_layer(name).output for name in layer_names] model = tf.keras.Model([vgg.input], outputs) return model . style_extractor = vgg_layers(style_layers) style_outputs = style_extractor(style_image*255) #Look at the statistics of each layer&#39;s output # for name, output in zip(style_layers, style_outputs): # print(name) # print(&quot; shape: &quot;, output.numpy().shape) # print(&quot; min: &quot;, output.numpy().min()) # print(&quot; max: &quot;, output.numpy().max()) # print(&quot; mean: &quot;, output.numpy().mean()) # print() . Helper functions . def gram_matrix(input_tensor): result = tf.linalg.einsum(&#39;bijc,bijd-&gt;bcd&#39;, input_tensor, input_tensor) input_shape = tf.shape(input_tensor) num_locations = tf.cast(input_shape[1]*input_shape[2], tf.float32) return result/(num_locations) . class StyleContentModel(tf.keras.models.Model): def __init__(self, style_layers, content_layers): super(StyleContentModel, self).__init__() self.vgg = vgg_layers(style_layers + content_layers) self.style_layers = style_layers self.content_layers = content_layers self.num_style_layers = len(style_layers) self.vgg.trainable = False def call(self, inputs): &quot;Expects float input in [0,1]&quot; inputs = inputs*255.0 preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs) outputs = self.vgg(preprocessed_input) style_outputs, content_outputs = (outputs[:self.num_style_layers], outputs[self.num_style_layers:]) style_outputs = [gram_matrix(style_output) for style_output in style_outputs] content_dict = {content_name:value for content_name, value in zip(self.content_layers, content_outputs)} style_dict = {style_name:value for style_name, value in zip(self.style_layers, style_outputs)} return {&#39;content&#39;:content_dict, &#39;style&#39;:style_dict} . extractor = StyleContentModel(style_layers, content_layers) results = extractor(tf.constant(content_image)) # print(&#39;Styles:&#39;) # for name, output in sorted(results[&#39;style&#39;].items()): # print(&quot; &quot;, name) # print(&quot; shape: &quot;, output.numpy().shape) # print(&quot; min: &quot;, output.numpy().min()) # print(&quot; max: &quot;, output.numpy().max()) # print(&quot; mean: &quot;, output.numpy().mean()) # print() # print(&quot;Contents:&quot;) # for name, output in sorted(results[&#39;content&#39;].items()): # print(&quot; &quot;, name) # print(&quot; shape: &quot;, output.numpy().shape) # print(&quot; min: &quot;, output.numpy().min()) # print(&quot; max: &quot;, output.numpy().max()) # print(&quot; mean: &quot;, output.numpy().mean()) . style_targets = extractor(style_image)[&#39;style&#39;] content_targets = extractor(content_image)[&#39;content&#39;] . image = tf.Variable(content_image) . def clip_0_1(image): return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0) . opt = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1) . style_weight=1e-2 content_weight=1e4 . def style_content_loss(outputs): style_outputs = outputs[&#39;style&#39;] content_outputs = outputs[&#39;content&#39;] style_loss = tf.add_n([tf.reduce_mean((style_outputs[name]-style_targets[name])**2) for name in style_outputs.keys()]) style_loss *= style_weight / num_style_layers content_loss = tf.add_n([tf.reduce_mean((content_outputs[name]-content_targets[name])**2) for name in content_outputs.keys()]) content_loss *= content_weight / num_content_layers loss = style_loss + content_loss return loss . @tf.function() def train_step(image): with tf.GradientTape() as tape: outputs = extractor(image) loss = style_content_loss(outputs) grad = tape.gradient(loss, image) opt.apply_gradients([(grad, image)]) image.assign(clip_0_1(image)) . Training . train_step(image) train_step(image) train_step(image) tensor_to_image(image) . Do 1000 iteration and save every 200th iteration image . import time with tf.device(&quot;/gpu:0&quot;): start = time.time() epochs = 10 steps_per_epoch = 100 step = 0 for n in range(epochs): for m in range(steps_per_epoch): step += 1 train_step(image) print(&quot;.&quot;, end=&#39;&#39;) display.clear_output(wait=True) display.display(tensor_to_image(image)) print(&quot;Train step: {}&quot;.format(step)) # save current generated image in the &quot;/output&quot; directory imageio.imwrite(&quot;output/&quot; + str(2*100) + &quot;.png&quot;, tensor_to_image(image)) end = time.time() print(&quot;Total time: {:.1f}&quot;.format(end-start)) . Train step: 1000 Total time: 634.3 . imageio.imwrite(&quot;output/&quot; + str(2*100) + &quot;.png&quot;, tensor_to_image(image)) . Total Variation Loss . I didn&#39;t learn this part so its like magic to me . def high_pass_x_y(image): x_var = image[:,:,1:,:] - image[:,:,:-1,:] y_var = image[:,1:,:,:] - image[:,:-1,:,:] return x_var, y_var . x_deltas, y_deltas = high_pass_x_y(content_image) plt.figure(figsize=(14,10)) plt.subplot(2,2,1) imshow(clip_0_1(2*y_deltas+0.5), &quot;Horizontal Deltas Original&quot;) plt.subplot(2,2,2) imshow(clip_0_1(2*x_deltas+0.5), &quot;Vertical Deltas Original&quot;) x_deltas, y_deltas = high_pass_x_y(image) plt.subplot(2,2,3) imshow(clip_0_1(2*y_deltas+0.5), &quot;Horizontal Deltas Styled&quot;) plt.subplot(2,2,4) imshow(clip_0_1(2*x_deltas+0.5), &quot;Vertical Deltas Styled&quot;) . plt.figure(figsize=(14,10)) sobel = tf.image.sobel_edges(content_image) plt.subplot(1,2,1) imshow(clip_0_1(sobel[...,0]/4+0.5), &quot;Horizontal Sobel-edges&quot;) plt.subplot(1,2,2) imshow(clip_0_1(sobel[...,1]/4+0.5), &quot;Vertical Sobel-edges&quot;) . def total_variation_loss(image): x_deltas, y_deltas = high_pass_x_y(image) return tf.reduce_sum(tf.abs(x_deltas)) + tf.reduce_sum(tf.abs(y_deltas)) . tf.image.total_variation(image).numpy() . array([114173.52], dtype=float32) . total_variation_weight=30 . @tf.function() def train_step(image): with tf.GradientTape() as tape: outputs = extractor(image) loss = style_content_loss(outputs) loss += total_variation_weight*tf.image.total_variation(image) grad = tape.gradient(loss, image) opt.apply_gradients([(grad, image)]) image.assign(clip_0_1(image)) . image = tf.Variable(content_image) . import time with tf.device(&quot;/gpu:0&quot;): start = time.time() epochs = 10 steps_per_epoch = 100 step = 0 for n in range(epochs): for m in range(steps_per_epoch): step += 1 train_step(image) print(&quot;.&quot;, end=&#39;&#39;) display.clear_output(wait=True) display.display(tensor_to_image(image)) print(&quot;Train step: {}&quot;.format(step)) end = time.time() print(&quot;Total time: {:.1f}&quot;.format(end-start)) . Train step: 1000 Total time: 834.3 . file_name = &#39;generated_image.png&#39; imageio.imwrite(&quot;output/&quot; + &#39;generated_image&#39; + &quot;.png&quot;, tensor_to_image(image)) . References: . The Neural Style Transfer algorithm was due to Gatys et al. (2015). The pre-trained network used in this implementation is a VGG network, which is due to Simonyan and Zisserman (2015). The whole code is basically from tensorflow website listed below with little changes(to save images and use gpu) . Leon A. Gatys, Alexander S. Ecker, Matthias Bethge, (2015). A Neural Algorithm of Artistic Style | Harish Narayanan, Convolutional neural networks for artistic style transfer. | DeepLearningAi(Coursera) (2020). Deep Learning Specialization | TensorFlow (2019). Neural style transfer | .",
            "url": "https://leejaeka.github.io/fastblog/fastpages/jupyter/meme/2020/12/02/Deep-Art-Gallery.html",
            "relUrl": "/fastpages/jupyter/meme/2020/12/02/Deep-Art-Gallery.html",
            "date": " • Dec 2, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Book Reviews and Storytime",
            "content": "Book Reviews . . Ill review later LOL . Storytime . 1. Monte Hall Problem . In this 1963 American tv show, the host Monty Hall proposes a game to the contestant. There are three closed doors. Two of the doors have goats behind them and one of the doors has a fancy car behind it. The contestants get to keep whatever is behind the door they choose. Once the contestant chooses one of the doors, Monty opens one of the unchosen doors showing a goat behind it. Then Monty asks the contestant if he/she wants to change their decision on the remaining two doors. Should the contestant change? . Most people will think the contestant has 1/2 chance of winning. I too thought this way but by switching, the contestant actually doubles their chance of winning. To see this most clearly, consider a similar test with 100 doors instead of 3. Now, once you choose a door, Monty opens 98 other doors showing goats and asks you if you want to switch. Obviously, you should switch to the other door because the original choice had 1/100 chance of winning but the other door is same as having had 99 choices to choose the correct door with 99% chance of winning. So in our original case, the door we chose initially has 1/3 chance of winning but choosing the other door has 2/3 chance. Hence doubling our chance of winning. If you are still not convinced, you can try out yourself here http://www.shodor.org/interactivate/activities/SimpleMontyHall/. . Reference . Books: . Naked Statistics: Stripping the Dread from the Data Book(2012) by Charles Wheelan | .",
            "url": "https://leejaeka.github.io/fastblog/fastpages/jupyter/meme/book_review/story/2020/11/28/Short-Storytime.html",
            "relUrl": "/fastpages/jupyter/meme/book_review/story/2020/11/28/Short-Storytime.html",
            "date": " • Nov 28, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "So I learned some new algorithms..",
            "content": "Introduction . Inception Net . You only look once algorithm . How do you detect multiple cars in a single image? . Object Detection .",
            "url": "https://leejaeka.github.io/fastblog/fastpages/jupyter/meme/2020/11/27/So-I-learned-some-new-algorithms.html",
            "relUrl": "/fastpages/jupyter/meme/2020/11/27/So-I-learned-some-new-algorithms.html",
            "date": " • Nov 27, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "White Wine Quality Exploratory Data Analysis With R",
            "content": "======================================================== . The white wine quality dataset consists of 13 variables, with 4898 observations. Note that the quality was determined by at least three different wine experts. Let us see what makes the best white wine! First we run the summary() function in R and get overwhelmed. . ## X fixed.acidity volatile.acidity citric.acid ## Min. : 1 Min. : 3.800 Min. :0.0800 Min. :0.0000 ## 1st Qu.:1225 1st Qu.: 6.300 1st Qu.:0.2100 1st Qu.:0.2700 ## Median :2450 Median : 6.800 Median :0.2600 Median :0.3200 ## Mean :2450 Mean : 6.855 Mean :0.2782 Mean :0.3342 ## 3rd Qu.:3674 3rd Qu.: 7.300 3rd Qu.:0.3200 3rd Qu.:0.3900 ## Max. :4898 Max. :14.200 Max. :1.1000 Max. :1.6600 ## residual.sugar chlorides free.sulfur.dioxide total.sulfur.dioxide ## Min. : 0.600 Min. :0.00900 Min. : 2.00 Min. : 9.0 ## 1st Qu.: 1.700 1st Qu.:0.03600 1st Qu.: 23.00 1st Qu.:108.0 ## Median : 5.200 Median :0.04300 Median : 34.00 Median :134.0 ## Mean : 6.391 Mean :0.04577 Mean : 35.31 Mean :138.4 ## 3rd Qu.: 9.900 3rd Qu.:0.05000 3rd Qu.: 46.00 3rd Qu.:167.0 ## Max. :65.800 Max. :0.34600 Max. :289.00 Max. :440.0 ## density pH sulphates alcohol ## Min. :0.9871 Min. :2.720 Min. :0.2200 Min. : 8.00 ## 1st Qu.:0.9917 1st Qu.:3.090 1st Qu.:0.4100 1st Qu.: 9.50 ## Median :0.9937 Median :3.180 Median :0.4700 Median :10.40 ## Mean :0.9940 Mean :3.188 Mean :0.4898 Mean :10.51 ## 3rd Qu.:0.9961 3rd Qu.:3.280 3rd Qu.:0.5500 3rd Qu.:11.40 ## Max. :1.0390 Max. :3.820 Max. :1.0800 Max. :14.20 ## quality ## Min. :3.000 ## 1st Qu.:5.000 ## Median :6.000 ## Mean :5.878 ## 3rd Qu.:6.000 ## Max. :9.000 . Fixed.volatile.acidity, citric.acid, fixed.acidity, total.sulfur.dioxide, chlorides, free.sulfur.dioxide, sulphates – I have no idea what there are since I’m not a chemist. The point of this project to explore with data analysis so it is okay. Rest variables are self-explanatory except pH which is how ripe the ingredient used for the wine was. We are most interested in what makes the differences in experts’ wine ratings. . . Univariate Plots Section . *It looks like Majority of our wines are quality between ‘5’ to ‘7’. There are less than 10 of the highest quality ‘9’ and dataset is normally distributed. . *Let’s look at some boring histograms of rest of the variables. . . ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. . . Boring as expected. . Some interesting points: . Since the dataset consists of real experts (human in the end), I think majority of their points comes from sweetness(sugar), acidity, alcohol and density. | Sugar had two main peaks at around 2 and 10. I guess majority of winemakers like to make their wine either sweet or not sweet. Most datas were skewed due to very few extreme outliers. | I have created total_acidity variable which does not make any sense but simplifies fixed, volatile and citric acids and free_rate which is proportion of free sulfur dioxide in total sulfur dioxide. Both for small dimension reduction purpose. | . One shot look at all bivariates . ## [1] &quot;residual.sugar&quot; &quot;chlorides&quot; &quot;density&quot; &quot;pH&quot; ## [5] &quot;sulphates&quot; &quot;alcohol&quot; &quot;quality&quot; &quot;total_acid&quot; ## [9] &quot;free_rate&quot; . . We can see that most scatterplots tends to form clusters with some outliers. Most interesting findings are… . Quality is most correlated with alcohol, density, chlorides . | Alcohol is highly correlated with chloride(-0.82) and sugar(-0.46) . | Sugar, alcohol and density are highly correlated . | Let’s have a closer look. . ## [1] &quot;(2,4]&quot; &quot;(4,7]&quot; &quot;(7,9]&quot; # 3,4 are “Low”, 5,6,7 are “Medium” 8,9 are “High” . . Boxplots of different qualities . So clearly, high quality wines tend to have higher alcohol, lower density and lower chlorides than other qualities of wine. . ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 7 x 5 ## quality med_alcohol med_desity med_chloride n ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 3 10.4 0.994 0.041 20 ## 2 4 10.1 0.994 0.046 163 ## 3 5 9.5 0.995 0.047 1457 ## 4 6 10.5 0.994 0.043 2198 ## 5 7 11.4 0.992 0.037 880 ## 6 8 12 0.992 0.036 175 ## 7 9 12.5 0.990 0.031 5 . We used median here since most variables were severly skewed. We can somewhat guess typical characteristics of particular qualities in this chart. We can also see clear difference between quality 3 and 9 instantly. . Multivariate Plots Section . . Multivariate Section . There’s a lot going on here. First we can easily confirm that indeed density, alcohol and sugar closely related. . 1. Higher sugar levels cover upper right region while lower sugar level covers lower left region. This means higher density and alcohol, higher the sugar level and vice versa. . 2. Alcohol and density are highly correlated. I suspect this is because alcohol is main source of reducing density since every other ingredients are likely to increase density. . 3. High quality wines have a cluster at the higher alcohol and lower density quadrant. In contrast, low quality wines have a cluster located further towards 1st and 3rd quadrants. Medium quality wines covers both area. . 4. No wines seem to exist lowest alcohol and lowest density region. . Multivariate Linear Regression . ## ## Call: ## lm(formula = quality ~ density + alcohol + chlorides, data = wine) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.5904 -0.5209 -0.0050 0.4832 3.0653 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -21.15016 6.16220 -3.432 0.000604 *** ## density 23.67087 6.07373 3.897 9.86e-05 *** ## alcohol 0.34312 0.01529 22.439 &lt; 2e-16 *** ## chlorides -2.38226 0.55760 -4.272 1.97e-05 *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.7946 on 4894 degrees of freedom ## Multiple R-squared: 0.1955, Adjusted R-squared: 0.195 ## F-statistic: 396.3 on 3 and 4894 DF, p-value: &lt; 2.2e-16 . Of course this is just a old textbook solution. It is terrible and very time consuming to try different variable combinations. Lets use random forest instead. . Random Forest Classifier on all quality [3,9] . ## randomForest 4.6-14 ## ## Call: ## randomForest(formula = factor(quality) ~ ., data = train, ntree = 500, importance = TRUE) ## Type of random forest: classification ## Number of trees: 500 ## No. of variables tried at each split: 3 ## ## OOB estimate of error rate: 31.73% ## Confusion matrix: ## 3 4 5 6 7 8 9 class.error ## 3 0 0 6 5 1 0 0 1.0000000 ## 4 0 24 57 43 2 0 0 0.8095238 ## 5 0 3 757 367 13 1 0 0.3365469 ## 6 0 2 216 1440 103 2 0 0.1832104 ## 7 0 0 12 314 391 3 0 0.4569444 ## 8 0 0 2 45 41 63 0 0.5827815 ## 9 0 0 0 2 3 0 0 1.0000000 . We got an accuracy of 69.4%. It is probably hard even for experts to distinguish quality level difference of 1 perfectly. . RFC(All quality) Interpretation (MeanDecreaseAccuracy, MeanDecreaseGini) . . To explain a little about the plots, MeanDecreaseAccuracy tells us how bad our predictions become if we were to omit that variable completly. MeanDecreaseGini tells us how clean the splits are if that variable was used to split the data. | This had me wonder if I bucket some quality together into only 3 qualities, ‘High’, ‘Medium’, and ‘Low’ I should be able to increase accuracy by a significant amount. | . Random Forest Classifier on bucketed quality (High, Med, Low) . ## ## Call: ## randomForest(formula = factor(quality.bucket) ~ ., data = train, ntree = 500, importance = TRUE) ## Type of random forest: classification ## Number of trees: 500 ## No. of variables tried at each split: 3 ## ## OOB estimate of error rate: 5.59% ## Confusion matrix: ## Low Qual. Med. Qual. High Qual. class.error ## Low Qual. 26 112 0 0.811594203 ## Med. Qual. 11 3610 3 0.003863135 ## High Qual. 0 93 63 0.596153846 . Ok we’ve achieved 94.46% accuracy. . RFC(bucketed) Interpretation (MeanDecreaseAccuracy, MeanDecreaseGini) . . ## predicted ## Low Qual. Med. Qual. High Qual. ## Low Qual. 9 36 0 ## Med. Qual. 7 904 0 ## High Qual. 0 14 10 . 93.82% accuracy on our test set! So it looks like there barely any overfitting and it generalizes really well too. We can also note that alcohol once again is most important by a significant amount. Followed by many acids and density &amp; sugar giving little meanings. . RFC(bucketed) Interpretation 2 (ROC Curve) . https://www.blopig.com/blog/2017/04/a-very-basic-introduction-to-random-forests-using-r/ (Reference) . . ## [[1]] ## [1] 0.8978966 ## ## [[1]] ## [1] 0.8655801 ## ## [[1]] ## [1] 0.9413354 . Red - Low Qual., Green - Med Qual., Blue - High Qual. Here we can see that model is very good at picking out the low quality wines but have harder time picking out high quality wines.In fact, if you recall the 7 level quality model, that model didn’t predict any sample to be high quality. So we can conclude that bad wines are easy to distinguish but best wines are hard to detect. . Reflection . The white wine set contains information on almost 5000 wine data which all have been evaluated by at least 3 different wine experts. We explored many variables and predicted that since density, chlorides, and alcohol had high correlation, their combination will define the quality of any wine. We also looked at an interesting relationship between chemicals like sugar makes density go up and alcohol go down. . Our random forest quantifier agreed with alcohol being important but disagreed with density and chloride being important. Instead it told us a lot of acids which had little to no correlation were very important. And proceeded to succesfully predict 94.46% on training set and 93.82% on test set. Also note it had harder time distinguishing higher quality wines than lower quality wines by looking at its MeanDecreaseAccuracy. Meaning other factors such as presentation or color may may be necessary divide the ‘best wine’ from good wines. . In conclusion, as predicted from my idea; acidity, sweetness, alcohol level but density plays a very important factor in determining high quality white wines. So although I’ve never had wine in my life, I can taste one and tell if it is good or not : ) .",
            "url": "https://leejaeka.github.io/fastblog/2020/11/24/White-Wine-Quality-Exploratory-Data-Analysis-with-R.html",
            "relUrl": "/2020/11/24/White-Wine-Quality-Exploratory-Data-Analysis-with-R.html",
            "date": " • Nov 24, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "LoL Prediction S10",
            "content": "Introduction . Let&#39;s predict who won the match given team composition and how long game played out . Get dataset . The dataset is a collection of League of Legends High Elo(Challenger, GM, Master, High Diamonds) Ranked games in Season 10, Korea(WWW), North America(NA), Eastern Europe(EUNE), and Western Europe(EUW) servers. These datas were collected from op.gg by web scrapping with python spyder. The latest game was played on Oct.16th on the dataset. In total there are 4028 unique games. Note that I&#39;ve used one-hot encoding hence [99,54,101,73,57,96,52,102,68,52] this list represents number of all unique champions used in each lanes [BlueTop, BlueJG, BlueMid, BlueAdc, BlueSup, RedTop, RedJg, RedMid, RedAdc, RedSup] respectivley. Note that there are in total 151 unique champions with &#39;Samira&#39; as the latest addition. . import pandas as pd df = pd.read_csv(&quot;games.csv&quot;) . Some Setups . import sys assert sys.version_info &gt;= (3, 5) # Scikit-Learn ≥0.20 is required import sklearn assert sklearn.__version__ &gt;= &quot;0.20&quot; try: # %tensorflow_version only exists in Colab. %tensorflow_version 2.x except Exception: pass # TensorFlow ≥2.0 is required import tensorflow as tf from tensorflow import keras assert tf.__version__ &gt;= &quot;2.0&quot; %load_ext tensorboard # Common imports import numpy as np import os # to make this notebook&#39;s output stable across runs np.random.seed(42) # To plot pretty figures %matplotlib inline import matplotlib as mpl import matplotlib.pyplot as plt mpl.rc(&#39;axes&#39;, labelsize=14) mpl.rc(&#39;xtick&#39;, labelsize=12) mpl.rc(&#39;ytick&#39;, labelsize=12) # Where to save the figures PROJECT_ROOT_DIR = &quot;.&quot; CHAPTER_ID = &quot;deep&quot; IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, &quot;images&quot;, CHAPTER_ID) os.makedirs(IMAGES_PATH, exist_ok=True) def save_fig(fig_id, tight_layout=True, fig_extension=&quot;png&quot;, resolution=300): path = os.path.join(IMAGES_PATH, fig_id + &quot;.&quot; + fig_extension) print(&quot;Saving figure&quot;, fig_id) if tight_layout: plt.tight_layout() plt.savefig(path, format=fig_extension, dpi=resolution) . The tensorboard extension is already loaded. To reload it, use: %reload_ext tensorboard . df.head(5) # First look at our dataset. Game_length includes some annoying string values instead of time value . game_length mmr result server team_1 team_2 timestamp . 0 25m 38s | NaN | Victory | na | Riven,Nidalee,Galio,Jhin,Pantheon | Camille,Olaf,Cassiopeia,Ezreal,Alistar | 2020-10-13 09:31:42 | . 1 25m 38s | NaN | Defeat | na | Teemo,Nidalee,Lucian,Caitlyn,Senna | Irelia,Hecarim,Cassiopeia,Jinx,Lulu | 2020-10-13 06:00:17 | . 2 25m 38s | NaN | Defeat | na | Malphite,Olaf,Taliyah,Ezreal,Alistar | Sylas,Lillia,Lucian,Senna,Pantheon | 2020-10-13 05:06:45 | . 3 25m 38s | NaN | Defeat | na | Neeko,Shen,Orianna,Kai&#39;Sa,Nautilus | Riven,Hecarim,Cassiopeia,Samira,Morgana | 2020-10-13 04:28:00 | . 4 25m 38s | NaN | Defeat | na | Fiora,Nunu &amp; Willump,Irelia,Jhin,Karma | Renekton,Elise,Kled,Jinx,Morgana | 2020-10-13 04:00:51 | . temp_df = df[[&#39;game_length&#39;, &#39;result&#39;, &#39;team_1&#39;, &#39;team_2&#39;]] # Select only interests blue = temp_df[&#39;team_1&#39;] red = temp_df[&#39;team_2&#39;] n = len(df) blue_champs = [] red_champs = [] for i in range(0,n): blue_champs += [blue[i].split(&#39;,&#39;)] red_champs += [red[i].split(&#39;,&#39;)] top = [] jg = [] mid = [] adc = [] sup = [] for i in range(0, n): top += [blue_champs[i][0]] jg += [blue_champs[i][1]] mid += [blue_champs[i][2]] adc += [blue_champs[i][3]] sup += [blue_champs[i][4]] top_2 = [] jg_2 = [] mid_2 = [] adc_2 = [] sup_2 = [] for i in range(0, n): top_2 += [red_champs[i][0]] jg_2 += [red_champs[i][1]] mid_2 += [red_champs[i][2]] adc_2 += [red_champs[i][3]] sup_2 += [red_champs[i][4]] . data = temp_df.drop(columns=[&#39;team_1&#39;,&#39;team_2&#39;]) # blue team data[&#39;top1&#39;] = top data[&#39;jg1&#39;] = jg data[&#39;mid1&#39;] = mid data[&#39;adc1&#39;] = adc data[&#39;sup1&#39;] = sup # red team data[&#39;top2&#39;] = top_2 data[&#39;jg2&#39;] = jg_2 data[&#39;mid2&#39;] = mid_2 data[&#39;adc2&#39;] = adc_2 data[&#39;sup2&#39;] = sup_2 . data.head(10) . game_length result top1 jg1 mid1 adc1 sup1 top2 jg2 mid2 adc2 sup2 . 0 25m 38s | Victory | Riven | Nidalee | Galio | Jhin | Pantheon | Camille | Olaf | Cassiopeia | Ezreal | Alistar | . 1 25m 38s | Defeat | Teemo | Nidalee | Lucian | Caitlyn | Senna | Irelia | Hecarim | Cassiopeia | Jinx | Lulu | . 2 25m 38s | Defeat | Malphite | Olaf | Taliyah | Ezreal | Alistar | Sylas | Lillia | Lucian | Senna | Pantheon | . 3 25m 38s | Defeat | Neeko | Shen | Orianna | Kai&#39;Sa | Nautilus | Riven | Hecarim | Cassiopeia | Samira | Morgana | . 4 25m 38s | Defeat | Fiora | Nunu &amp; Willump | Irelia | Jhin | Karma | Renekton | Elise | Kled | Jinx | Morgana | . 5 25m 38s | Defeat | Irelia | Karthus | Sylas | Samira | Nautilus | Riven | Kayn | Akali | Miss Fortune | Galio | . 6 25m 38s | Defeat | Galio | Kindred | Syndra | Ezreal | Blitzcrank | Camille | Fiddlesticks | Twisted Fate | Jhin | Morgana | . 7 25m 38s | Defeat | Poppy | Ekko | Sylas | Samira | Blitzcrank | Lucian | Lillia | Lulu | Caitlyn | Alistar | . 8 25m 38s | Defeat | Shen | Lillia | Samira | Lucian | Soraka | Taric | Master Yi | Riven | Ezreal | Lulu | . 9 25m 38s | Defeat | Ornn | Graves | Sylas | Lucian | Alistar | Irelia | Hecarim | Akali | Senna | Leona | . from sklearn.preprocessing import OneHotEncoder #y = pd.get_dummies(data.top1, prefix=&#39;top1&#39;) enc = OneHotEncoder() only_champs = data.drop(columns=[&#39;game_length&#39;, &#39;result&#39;]) only_champs.head(5) only_champs_onehot = enc.fit_transform(only_champs) . enc.get_params() . {&#39;categories&#39;: &#39;auto&#39;, &#39;drop&#39;: None, &#39;dtype&#39;: numpy.float64, &#39;handle_unknown&#39;: &#39;error&#39;, &#39;sparse&#39;: True} . import re date_str = data.game_length m = 2717 #longest games are 45m 17s for i in range(len(date_str)): if type(date_str[i]) == str: p = re.compile(&#39; d*&#39;) min = float(p.findall(date_str[i][:2])[0]) temp = p.findall(date_str[i][-3:]) for j in temp: if j != &#39;&#39;: sec = float(j) break date_str[i] = (60*min+sec)/m else: date_str[i] = date_str[i]/m # print(date_str[i]) # print(len(date_str)) . #except_champs = data.drop(columns=[&#39;result&#39;,&#39;top1&#39;,&#39;jg1&#39;,&#39;mid1&#39;,&#39;adc1&#39;,&#39;sup1&#39;,&#39;top2&#39;,&#39;jg2&#39;,&#39;mid2&#39;,&#39;adc2&#39;,&#39;sup2&#39;]) sparse_to_df = pd.DataFrame.sparse.from_spmatrix(only_champs_onehot) print(sparse_to_df.shape) print(date_str.shape) X = date_str.to_frame().join(sparse_to_df).dropna() X = np.asarray(X).astype(&#39;float32&#39;) . (4028, 754) (4028,) . y = data[&#39;result&#39;] for i in range(len(y)): if y[i] == &quot;Victory&quot;: y[i] = 1 else: y[i] = 0 . y = np.asarray(y).astype(&#39;float32&#39;) . Datas are one hot encoded and cleaned up. Let&#39;s train test split . from sklearn.model_selection import train_test_split import math X_train_full, X_test, y_train_full, y_test = train_test_split(X,y,test_size=0.2, random_state=42) #len(X_train) = 3222 l = math.floor(3222*0.8) X_valid, X_train = X_train_full[:l], X_train_full[l:] y_valid, y_train = y_train_full[:l], y_train_full[l:] print(y_valid.shape) print(X_valid.shape) . (2577,) (2577, 755) . Let&#39;s try Neural Network with dropouts . model = keras.models.Sequential([ keras.layers.Flatten(input_shape=(755,)), keras.layers.Dense(30, activation=&quot;relu&quot;, name=&quot;layer_1&quot;), keras.layers.Dropout(rate=0.2), keras.layers.Dense(16, activation=&quot;relu&quot;, name=&quot;layer_2&quot;), keras.layers.Dropout(rate=0.2), keras.layers.Dense(16, activation=&quot;relu&quot;, name=&quot;layer_3&quot;), keras.layers.Dropout(rate=0.2), keras.layers.Dense(1, activation=&quot;sigmoid&quot;, name=&quot;layer_4&quot;) ]) . model.compile(loss=&quot;binary_crossentropy&quot;, optimizer=&quot;adam&quot;, metrics=[&quot;accuracy&quot;]) model.summary() . Model: &#34;sequential&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= flatten (Flatten) (None, 755) 0 _________________________________________________________________ layer_1 (Dense) (None, 30) 22680 _________________________________________________________________ dropout (Dropout) (None, 30) 0 _________________________________________________________________ layer_2 (Dense) (None, 16) 496 _________________________________________________________________ dropout_1 (Dropout) (None, 16) 0 _________________________________________________________________ layer_3 (Dense) (None, 16) 272 _________________________________________________________________ dropout_2 (Dropout) (None, 16) 0 _________________________________________________________________ layer_4 (Dense) (None, 1) 17 ================================================================= Total params: 23,465 Trainable params: 23,465 Non-trainable params: 0 _________________________________________________________________ . model.fit(X_train, y_train, epochs=50, batch_size=1) . test_loss, test_acc = model.evaluate(X_test, y_test) print(&#39;accuracy&#39;, test_acc) . 26/26 [==============================] - 0s 806us/step - loss: 3.8032 - accuracy: 0.6613 accuracy 0.6612903475761414 . We got about 0.661 accuracy with just raw neural network with dropouts. . Let&#39;s try random forests . from sklearn.ensemble import RandomForestClassifier rnd_clf = RandomForestClassifier(n_estimators=2000, max_leaf_nodes=32, n_jobs=-1) rnd_clf.fit(X_train, y_train) . RandomForestClassifier(max_leaf_nodes=32, n_estimators=2000, n_jobs=-1) . y_val_pred = rnd_clf.predict(X_valid) . val_acc = np.sum(y_val_pred == y_valid)/len(y_valid) print(&quot;validation accuracy: &quot;+str(val_acc)) . validation accuracy: 0.7710516103996896 . y_test_pred = rnd_clf.predict(X_test) test_acc = np.sum(y_test_pred == y_test)/len(y_test) print(&quot;test accuracy: &quot;+str(test_acc)) . test accuracy: 0.7704714640198511 . Immediate improvement by almost 10% with random forest classifier! . Model Explanability . Let&#39;s look at what we were mostly interested. What are some best team compositions! . # from eli5.sklearn import PermutationImportance # perm = PermutationImportance(rnd_clf, random_state=42).fit(X_valid, y_valid) # eli5.show_weights(perm, feature_names=X_valid.columns.tolist()) # Will take billions years to compute . Let&#39;s try SHAP summary . import shap explainer = shap.TreeExplainer(rnd_clf) shap_values = explainer.shap_values(X_valid) shap.summary_plot(shap_values[1], X_valid) . We see that feature 0 (game length) tells us that the game favors blue team winning more when game is shorter which is unexpected. Note that it it not significant at all since SHAP value is -0.02 ~ 0.4 at most. | Generally, since all the values are 0 are 1, we can see clear 1-red and 0-blue (When it&#39;s 0 it has no impact on the prediction) | We can see feature 156(blue Mid Akali) helped RED team win more | Whereas Feature 462(red Top Tryndamere) helps the BLUE team win significantly more haha | From this chart, we can clearly see that each champion has very consistent and predictable contribution to their team&#39;s chance of winning | . Note that . 119 Kindred blue jg | 638 Caitlyn red adc | 60 Renekton blue top | 162 Cassiopeia blue mid | 535 Akali red mid | 376 Thresh blue support | 471 Volibear red top | 31 Jax blue top | 654 Kalista red adc | 290 Miss Fortune blue adc | 259 Ashe blue adc | 360 Rakan blue support | 210 Orianna blue mid | 462 Tryndamere red top | 445 Riven red top | 425 Lucian red top | 715 Janna red support | 156 Akali blue mid | 72 Sylas blue top | . Therefore our best teamp comp impacting positively on winning is ... . (Top)Renekton/Jax/Sylas (Jg)Kindred (Mid) Cassiopeia/Orianna (Adc)MF/Ashe (Sup)Thresh/Rakan | . Meanwhile worst team comp impacting negatively on winning is ... . (Top)Volibear/Trynd/Riven/Lucian (Mid)Akali (Adc)Caitlyn/Kalista (Sup)Janna | . We can also note that Jg role seem to not matter much.. : ) . def find_champ(i): temp_list = [99,54,101,73,57,96,52,102,68,52] for num in range(len(temp_list)): if (i-temp_list[num] &lt;= 0): return enc.categories_[num][i-1] else: i = i-temp_list[num] . # list_champ = [119, 638,60,162,535,376,471,31,654,290,259,360,210,462,445,425,715,156,72] # for champ in list_champ: # lane = &#39;&#39; # if champ &lt;= 99 or 385&lt;=champ&lt;=480: # lane = &quot;top&quot; # elif 100 &lt;= champ &lt;=153 or 481&lt;=champ&lt;=532: # lane = &quot;jg&quot; # elif 154 &lt;= champ &lt;=255 or 533&lt;=champ&lt;=634: # lane= &quot;mid&quot; # elif 256 &lt;= champ &lt;=327 or 635&lt;=champ&lt;=702: # lane= &quot;adc&quot; # else: # lane = &quot;support&quot; # team = &quot;blue&quot; if champ &lt;= 384 else &quot;red&quot; # print(champ, find_champ(champ), team, lane) #print(len(enc.categories_[0])) 99 #print(len(enc.categories_[1])) 54 //153 #print(len(enc.categories_[2])) 101 //254 #print(len(enc.categories_[3])) 73 //327 #print(len(enc.categories_[4])) 57 // UP TO 384 is blue team #print(len(enc.categories_[5])) 96 //480 #print(len(enc.categories_[6])) 52 //532 #print(len(enc.categories_[7])) 102 //634 #print(len(enc.categories_[8])) 68 //702 #print(len(enc.categories_[9])) 52 //754 . What if we didn&#39;t have game length, just champion compositions only? . X_1 = sparse_to_df . X_train_full, X_test, y_train_full, y_test = train_test_split(X_1,y,test_size=0.2, random_state=42) #len(X_train) = 3222 l = math.floor(3222*0.8) X_valid, X_train = X_train_full[:l], X_train_full[l:] y_valid, y_train = y_train_full[:l], y_train_full[l:] print(y_valid.shape) print(X_valid.shape) . (2577,) (2577, 754) . rnd_clf = RandomForestClassifier(n_estimators=2000, max_leaf_nodes=32, n_jobs=-1) rnd_clf.fit(X_train, y_train) . RandomForestClassifier(max_leaf_nodes=32, n_estimators=2000, n_jobs=-1) . y_val_pred = rnd_clf.predict(X_valid) val_acc = np.sum(y_val_pred == y_valid)/len(y_valid) print(&quot;validation accuracy: &quot;+str(val_acc)) . validation accuracy: 0.7691113698098564 . y_test_pred = rnd_clf.predict(X_test) test_acc = np.sum(y_test_pred == y_test)/len(y_test) print(&quot;test accuracy: &quot;+str(test_acc)) . test accuracy: 0.7692307692307693 . Surprisingly, accuracy only drops less than 0.01. We can conclude that planning out a team comp based on champion&#39;s strength on early vs late game does not help win more. This can be explained by an example. Let&#39;s say I picked kayle which is the best late game champion. We may win games with longer duration more but will lose more short games due to her weakness early. So the overall win rate balances out. . Conclusion . best: (Top)Renekton/Jax/Sylas (Jg)Kindred (Mid) Cassiopeia/Orianna (Adc)MF/Ashe (Sup)Thresh/Rakan | worst: (Top)Volibear/Trynd/Riven/Lucian (Mid)Akali (Adc)Caitlyn/Kalista (Sup)Janna | . We know that in the world of solo queue, picking the above champions will not gurantee a win. Sometimes people are autofilled, meaning they aren&#39;t playing on their best role. People may disconnect, resulting in games favoring the opposite team. There are too many unknown factors like this, making it impossible to predict 100% of the game outcomes correctly. . As a former high elo NA player myself, I can say that generally, the &#39;best team&#39; above have champions that doesn&#39;t get countered too often and is a good pick into anything. (This may not be the case for top because I&#39;ve never really cared about top lanes as a support player :). But for &#39;worst team&#39; champions, they are often easily countered. (Especially bottom lane) . The biggest surprise was blue team wins more early and red team wins more late (Very slightly but certainly) for some reason. Also jg mattering the least was a surprise as well. .",
            "url": "https://leejaeka.github.io/fastblog/fastpages/jupyter/2020/10/28/lolpredict.html",
            "relUrl": "/fastpages/jupyter/2020/10/28/lolpredict.html",
            "date": " • Oct 28, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Renekton Croc plush detector",
            "content": "reptile_types = &#39;crocodile&#39;,&#39;alligator plush&#39;, &#39;renekton&#39; path = Path(&#39;reptiles&#39;) . if not path.exists(): path.mkdir() for o in reptile_types: dest = (path/o) dest.mkdir(exist_ok=True) results = search_images_bing(key, f&#39;{o}&#39;) download_images(dest, urls=results.attrgot(&#39;content_url&#39;)) . fns = get_image_files(path) fns . (#416) [Path(&#39;reptiles/alligator plush/00000000.jpg&#39;),Path(&#39;reptiles/alligator plush/00000001.jpg&#39;),Path(&#39;reptiles/alligator plush/00000002.jpg&#39;),Path(&#39;reptiles/alligator plush/00000003.jpg&#39;),Path(&#39;reptiles/alligator plush/00000004.jpeg&#39;),Path(&#39;reptiles/alligator plush/00000005.jpg&#39;),Path(&#39;reptiles/alligator plush/00000006.jpg&#39;),Path(&#39;reptiles/alligator plush/00000007.jpg&#39;),Path(&#39;reptiles/alligator plush/00000008.jpg&#39;),Path(&#39;reptiles/alligator plush/00000009.jpg&#39;)...] . failed = verify_images(fns) failed.map(Path.unlink) . (#0) [] . class DataLoaders(GetAttr): num_workers=0 def __init__(self, *loaders): self.loaders = loaders def __getitem__(self, i): return self.loaders[i] train,valid = add_props(lambda i, self: self[i]) . reptiles = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128)) . dls = reptiles.dataloaders(path) dls.valid.show_batch(max_n=4, nrows=1) . reptiles = reptiles.new(item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms()) dls = reptiles.dataloaders(path, num_workers=0) # &lt;- num_workers=0 to prevent window error . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 1.455003 | 0.249432 | 0.084337 | 00:18 | . epoch train_loss valid_loss error_rate time . 0 | 0.104521 | 0.049535 | 0.024096 | 00:18 | . 1 | 0.068319 | 0.012980 | 0.012048 | 00:18 | . 2 | 0.052283 | 0.011862 | 0.000000 | 00:19 | . 3 | 0.041685 | 0.010840 | 0.000000 | 00:19 | . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . Result is very good . # cleaner # for idx in cleaner.delete(): cleaner.fns[idx].unlink() # delete . Let&#39;s test . my_renek = PILImage.create(&quot;renek_plush.png&quot;) display(my_renek.to_thumb(256,256)) . pred, pred_idx, probs =learn.predict(my_renek) f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; . &#39;Prediction: alligator plush; Probability: 0.9391&#39; . Very good. It is very accurate since my drawing of a plush is very realistic. . renek = PILImage.create(&quot;renek_test.png&quot;) display(renek.to_thumb(256,256)) pred, pred_idx, probs =learn.predict(renek) f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; . &#39;Prediction: renekton; Probability: 0.9834&#39; . Easily recognizes my drawing of Renekton as well. I guess I&#39;m an artist . renek_withoutbg = PILImage.create(&quot;renek_test1.png&quot;) display(renek_withoutbg.to_thumb(256,256)) pred, pred_idx, probs =learn.predict(renek_withoutbg) f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; . &#39;Prediction: renekton; Probability: 0.9674&#39; . Expected the model to predict plush becasue I removed the background but it&#39;s too smart. (In dataset a lot of plush had empty white background contrast to lots of Renekton images having dark backgrounds) . beard = PILImage.create(&quot;beard.jpg&quot;) display(beard.to_thumb(200,200)) pred, pred_idx, probs =learn.predict(beard) f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; . &#39;Prediction: alligator plush; Probability: 0.8644&#39; . Indeed I am an alligator plush with my fake beard! . learn.export() . RUN CODE BELOW TO MAKE YOUR OWN TEST (Download export.pkl file on my github) . from fastai.vision.widgets import * btn_upload = widgets.FileUpload() out_pl = widgets.Output() lbl_pred = widgets.Label() . path = Path(&#39;&#39;) learn_inf = load_learner(path/&#39;export.pkl&#39;, cpu=True) . def on_data_change(change): lbl_pred.value = &#39;&#39; img = PILImage.create(btn_upload.data[-1]) out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) pred,pred_idx,probs = learn_inf.predict(img) lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; . btn_upload.observe(on_data_change, names=[&#39;data&#39;]) display(VBox([widgets.Label(&#39;Feed me a reptile photo!&#39;), btn_upload, out_pl, lbl_pred])) .",
            "url": "https://leejaeka.github.io/fastblog/2020/10/27/croc.html",
            "relUrl": "/2020/10/27/croc.html",
            "date": " • Oct 27, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "City Detector",
            "content": "Let&#39;s make app that recognizes Coquitlam! . import os key = os.environ.get(&#39;AZURE_SEARCH_KEY&#39;, &#39;39f25aae8d744a528b964a94a4af8b58&#39;) . Let&#39;s get the images of each city . city_types = &#39;seoul city&#39;,&#39;coquitlam&#39;,&#39;paris city&#39;, &#39;new york city&#39; path = Path(&#39;cities&#39;) . if not path.exists(): path.mkdir() for o in city_types: dest = (path/o) dest.mkdir(exist_ok=True) results = search_images_bing(key, f&#39;{o}&#39;) download_images(dest, urls=results.attrgot(&#39;content_url&#39;)) . fns = get_image_files(path) fns . (#596) [Path(&#39;cities/coquitlam/00000000.jpg&#39;),Path(&#39;cities/coquitlam/00000001.jpg&#39;),Path(&#39;cities/coquitlam/00000002.png&#39;),Path(&#39;cities/coquitlam/00000003.jpg&#39;),Path(&#39;cities/coquitlam/00000004.jpg&#39;),Path(&#39;cities/coquitlam/00000005.jpg&#39;),Path(&#39;cities/coquitlam/00000006.jpg&#39;),Path(&#39;cities/coquitlam/00000007.jpg&#39;),Path(&#39;cities/coquitlam/00000008.jpg&#39;),Path(&#39;cities/coquitlam/00000009.jpg&#39;)...] . failed = verify_images(fns) failed . (#16) [Path(&#39;cities/coquitlam/00000067.jpg&#39;),Path(&#39;cities/coquitlam/00000077.JPG&#39;),Path(&#39;cities/coquitlam/00000079.jpg&#39;),Path(&#39;cities/coquitlam/00000135.jpg&#39;),Path(&#39;cities/new york city/00000010.jpg&#39;),Path(&#39;cities/new york city/00000014.jpg&#39;),Path(&#39;cities/new york city/00000020.jpg&#39;),Path(&#39;cities/new york city/00000026.jpg&#39;),Path(&#39;cities/new york city/00000029.jpg&#39;),Path(&#39;cities/new york city/00000037.jpg&#39;)...] . failed.map(Path.unlink) . (#16) [None,None,None,None,None,None,None,None,None,None...] . Let&#39;s load the data . class DataLoaders(GetAttr): def __init__(self, *loaders): self.loaders = loaders def __getitem__(self, i): return self.loaders[i] train,valid = add_props(lambda i, self: self[i]) . cities = DataBlock( blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(valid_pct=0.2, seed=42), get_y=parent_label, item_tfms=Resize(128)) . dls = cities.dataloaders(path) dls.valid.show_batch(max_n=8, nrows = 2) . Let&#39;s scale and augment the datas . cities = cities.new(item_tfms=RandomResizedCrop(224, min_scale=0.5), batch_tfms=aug_transforms()) dls = cities.dataloaders(path, num_workers=0) # &lt;- num_workers=0 to prevent window error . Let&#39;s build and run a CNN model . learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(4) . epoch train_loss valid_loss error_rate time . 0 | 2.187395 | 1.315027 | 0.482759 | 00:42 | . epoch train_loss valid_loss error_rate time . 0 | 1.307873 | 0.871226 | 0.336207 | 00:41 | . 1 | 1.064780 | 0.831430 | 0.241379 | 00:41 | . 2 | 0.876646 | 0.767134 | 0.215517 | 00:41 | . 3 | 0.784991 | 0.738216 | 0.224138 | 00:49 | . Let&#39;s look at the confusion matrix . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . We got an accuracy of 26/90 = 71% (rounded) . interp.plot_top_losses(2,nrows=2) . Let&#39;s try to clean up the dataset . cleaner = ImageClassifierCleaner(learn) cleaner . for idx in cleaner.delete(): cleaner.fns[idx].unlink() # delete . dls = cities.dataloaders(path, num_workers=0) learn = cnn_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(5) . epoch train_loss valid_loss error_rate time . 0 | 1.933403 | 1.322945 | 0.460870 | 00:38 | . epoch train_loss valid_loss error_rate time . 0 | 1.258363 | 0.800413 | 0.347826 | 00:37 | . 1 | 1.014135 | 0.660854 | 0.243478 | 00:38 | . 2 | 0.851025 | 0.609896 | 0.243478 | 00:38 | . 3 | 0.725140 | 0.591347 | 0.217391 | 00:37 | . 4 | 0.623130 | 0.582418 | 0.226087 | 00:37 | . Valid_loss doesn&#39;t decrease so we stop . interp = ClassificationInterpretation.from_learner(learn) interp.plot_confusion_matrix() . interp.plot_top_losses(6,nrows=2) . It looks like it has a hard time highlighting seoul city&#39;s characteristics as most error comes from seoul images. Suspected factors include seoul having new york like buildings, mountains like coquitlam and brick structures like paris city. . Ignore Below (Deployment IPR) . learn.export() . path = Path() path.ls(file_exts=&#39;.pkl&#39;) . (#1) [Path(&#39;export.pkl&#39;)] . learn_inf = load_learner(path/&#39;export.pkl&#39;) . learn_inf.dls.vocab . [&#39;coquitlam&#39;, &#39;new york city&#39;, &#39;paris city&#39;, &#39;seoul city&#39;] . btn_upload = widgets.FileUpload() btn_upload . img = PILImage.create(btn_upload.data[-1]) . out_pl = widgets.Output() out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) out_pl . pred,pred_idx,probs = learn_inf.predict(img) #hide_output lbl_pred = widgets.Label() lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; lbl_pred . Classify Button &amp; Event Handler . btn_run = widgets.Button(description=&#39;Classify&#39;) btn_run . def on_click_classify(change): img = PILImage.create(btn_upload.data[-1]) out_pl.clear_output() with out_pl: display(img.to_thumb(128,128)) pred,pred_idx,probs = learn_inf.predict(img) lbl_pred.value = f&#39;Prediction: {pred}; Probability: {probs[pred_idx]:.04f}&#39; btn_run.on_click(on_click_classify) .",
            "url": "https://leejaeka.github.io/fastblog/fastpages/jupyter/2020/10/27/city.html",
            "relUrl": "/fastpages/jupyter/2020/10/27/city.html",
            "date": " • Oct 27, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://leejaeka.github.io/fastblog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am currently a student at the University of Toronto studying Mathematic, Statistic and Computer Science. I am currently studying data science and machine learning : ) . Tip: Check out my jellyfish tank on my other website! www.jaekanglee.com .",
          "url": "https://leejaeka.github.io/fastblog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://leejaeka.github.io/fastblog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}